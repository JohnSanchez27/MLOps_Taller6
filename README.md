# Taller CI/CD + Observabilidad para API de IA

Este proyecto implementa una arquitectura completa con Docker, Prometheus, Grafana y despliegue listo para Kubernetes, basada en una API de predicciÃ³n desarrollada con FastAPI y un modelo de clasificaciÃ³n de pingÃ¼inos.

---

## ğŸ” DescripciÃ³n General

La soluciÃ³n incluye:

- **API FastAPI** para predicciÃ³n de especies de pingÃ¼inos
- **Modelo entrenado (`model.pkl`)** usando `train_model.py`
- **Endpoint `/predict`** para recibir inputs y retornar la especie
- **Endpoint `/metrics`** para exponer mÃ©tricas Prometheus
- **LoadTester** para simular trÃ¡fico de peticiones
- **Prometheus** para monitorear mÃ©tricas en tiempo real
- **Grafana** para visualizar las mÃ©tricas
- **Docker Compose** para orquestar todos los servicios
- **ImÃ¡genes publicadas en Docker Hub**
- **Listo para ser desplegado en MicroK8s**

---

## ğŸ“ Estructura del Proyecto

```
TALLER_6/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ Dockerfile_app
â”‚   â”œâ”€â”€ requirements_app.txt
â”‚   â”œâ”€â”€ train_model.py
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py
â”‚       â””â”€â”€ model.pkl
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ penguin_api_dashboard.json
â”œâ”€â”€ loadtester/
â”‚   â”œâ”€â”€ Dockerfile_loadtester
â”‚   â”œâ”€â”€ main_loadtester.py
â”‚   â””â”€â”€ requirements_loadtester.txt
â”œâ”€â”€ manifests/
â”‚   â”œâ”€â”€ api-deployment.yaml
â”‚   â””â”€â”€ api-service.yaml
â”‚   â””â”€â”€ grafana-deployment.yaml
â”‚   â””â”€â”€ grafana-service.yaml
â”‚   â””â”€â”€ loadtester-deployment.yaml
â”‚   â””â”€â”€ prometheus-cm0-configmap.yaml
â”‚   â””â”€â”€ prometheus-deployment.yaml
â”‚   â””â”€â”€ prometheus-service.yaml
â”œâ”€â”€ prometheus/
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ grafana-config/
â”‚       â””â”€â”€ datasources/
â”‚           â””â”€â”€ datasource.yml
â”œâ”€â”€ docker-compose.yml
```

---

## ğŸš€ Instrucciones de EjecuciÃ³n

### 1. ConstrucciÃ³n y despliegue local

```bash
docker-compose up --build
```

Servicios disponibles:
- API: Es la API principal que ofrece un endpoint /predict para recibir atributos morfolÃ³gicos de un pingÃ¼ino y retornar la especie predicha (Adelie, Chinstrap o Gentoo). TambiÃ©n expone /metrics para exponer datos monitoreables en formato Prometheus. Fue desarrollada con FastAPI y sirve un modelo previamente entrenado y serializado (model.pkl).

 http://localhost:8000/docs

![FastApi](imagenes/FastApi.png)

- Prometheus: Prometheus es el sistema de monitoreo que consulta la API cada 5 segundos para scrapear las mÃ©tricas disponibles en /metrics. Estas mÃ©tricas incluyen nÃºmero total de peticiones, latencias y predicciones por clase. Prometheus guarda estas mÃ©tricas y permite hacer consultas personalizadas para anÃ¡lisis.

http://localhost:9090

![prometheus](imagenes/prometheus.png)

- Grafana: http://localhost:3000 (user: `admin`, pass: `admin`)

Grafana permite visualizar grÃ¡ficamente las mÃ©tricas capturadas por Prometheus. A travÃ©s de un dashboard importable, puedes monitorear peticiones por segundo, latencia promedio, y distribuciÃ³n por especie predicha. El dashboard personalizado estÃ¡ disponible en grafana/penguin_api_dashboard.json.

![grafana](imagenes/grafana.png)

-  LoadTester (sin interfaz):
Este servicio es un contenedor que envÃ­a peticiones POST al endpoint /predict de la API cada segundo con datos aleatorios simulados. Su funciÃ³n es generar carga de uso realista para permitir pruebas de rendimiento y monitoreo continuo. No requiere intervenciÃ³n manual.

### 2. MÃ©tricas implementadas

- `predict_requests_total`
- `predict_request_latency_seconds`
- `predicted_class`

Visualizables en Grafana con el dashboard incluido (`penguin_api_dashboard.json`).

---

## ğŸ³ ImÃ¡genes Docker pÃºblicas

- `johnsanchez27/penguin-api:latest`
- `johnsanchez27/penguin-loadtester:latest`

![Captura de Docker Hub](imagenes/dockerhub.png)



---

## ğŸ“ˆ Dashboard Grafana

Archivo `penguin_api_dashboard.json` disponible para importar directamente en Grafana.

## Github Actions

Se logrÃ³ implementar el GitHub actions mediante la carpeta .github y el archivo dentro de ella .yml, se le ha indicado a Github que cada vez que se hace push a la rama main, Ã©l vuelve a levantar el contenedor de entrenamiento, y hace push en DockerHub actualizando la imagen que se utiliza. Esto nos permite tener una integraciÃ³n continua, para lograr la actualizaciÃ³n en DockerHub fue necesario definir variables de entorno de tipo secreto con el username y el password

![GitHubActions](imagenes/Jobs_Github.png)

### Secrets
![GitHubActions](imagenes/Secrets_Github.png)

Logrando esto, el workflow ha sido exitoso como se muestra a continuaciÃ³n

![GitHubActions](imagenes/Workflow_Exitoso.png)


---

## â˜¸ï¸ Listo para MicroK8s

Se procede a la creaciÃ³n de un docker-composeku.yaml con el cual se montaron las imÃ¡genes de FastAPI y de loadtester, grafana y prometheus, con el fin de levantar los servicios a traves de kubernetes y se siguieron estos pasos

1. Crear el archivo docker-compose.yaml
2. Desplegar microK8s
   
```bash

microk8s kubectl apply -f docker-compose.yaml

```
3. Verificar los pods y servicios
```bash

microk8s kubectl get pods
microk8s kubectl get services

```

4. Acceder a los servicios
Usa los puertos expuestos para acceder y utilizar cada uno de los servicios



